{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cic0269_natural_language_processing/blob/main/lectures/cap13_2_embeddings_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capítulo 13 - Word Embeddings\n",
        "\n",
        "Atenção: esse notebook foi adaptado do [tutorial](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) disponível na documentação do Keras.\n",
        "\n",
        "## 13.1. Transferência por Aprendizado via Word2Vec"
      ],
      "metadata": {
        "id": "hebpaQlpKSyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBhH-LrUBPQC"
      },
      "outputs": [],
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install -U gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KdvNPSjGbgpV"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Activation,Dropout,SimpleRNN,BatchNormalization,RNN,Flatten,Input,LSTM,Bidirectional\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, vamos importar os embeddings pré-treinados do corpus da Google, conhecido como ```GoogleNews-vectors-negative300.bin```. Esse corpus possui\n",
        "\n"
      ],
      "metadata": {
        "id": "0i5M2jASK2V9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LR_xXvK8BRWR"
      },
      "outputs": [],
      "source": [
        "ds_train = tfds.load('snli', split='train[50%:]', shuffle_files=True)\n",
        "ds_valid = tfds.load('snli', split='validation', shuffle_files=False)\n",
        "ds_test = tfds.load('snli', split='test', shuffle_files=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V6WDpjh1BS8J"
      },
      "outputs": [],
      "source": [
        "df_train = tfds.as_dataframe(ds_train)\n",
        "df_valid = tfds.as_dataframe(ds_valid)\n",
        "df_test = tfds.as_dataframe(ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fjJTCUMjBUtR"
      },
      "outputs": [],
      "source": [
        "def preprocessDataFrame(df):\n",
        "\n",
        "    dic = {}\n",
        "    dic['premise_hypothesis'] = []\n",
        "    dic['label'] = []\n",
        "\n",
        "    hypothesis = [x.decode('utf-8') for x in df['hypothesis'].values]\n",
        "    premise = [x.decode('utf-8') for x in df['premise'].values]\n",
        "\n",
        "    for idx,sentence in enumerate(premise):\n",
        "        dic['premise_hypothesis'].append(premise[idx]+\" \"+hypothesis[idx])\n",
        "        dic['label'].append(df['label'][idx])\n",
        "        \n",
        "    return pd.DataFrame.from_dict(dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7m7IV2NMBWHA"
      },
      "outputs": [],
      "source": [
        "df_train = preprocessDataFrame(df_train)\n",
        "df_valid = preprocessDataFrame(df_valid)\n",
        "df_test = preprocessDataFrame(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_7_5cN9NBXyh"
      },
      "outputs": [],
      "source": [
        "df_train['label'] = pd.Categorical(df_train['label'])\n",
        "y_train_int = df_train['label'].cat.codes\n",
        "\n",
        "df_valid['label'] = pd.Categorical(df_valid['label'])\n",
        "y_valid_int = df_valid['label'].cat.codes\n",
        "\n",
        "df_test['label'] = pd.Categorical(df_test['label'])\n",
        "y_test_int = df_test['label'].cat.codes\n",
        "\n",
        "y_train = to_categorical(y_train_int)\n",
        "y_valid = to_categorical(y_valid_int)\n",
        "y_test = to_categorical(y_test_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NsIFIfO5HJhn"
      },
      "outputs": [],
      "source": [
        "train_sentences = df_train['premise_hypothesis'].to_list()\n",
        "\n",
        "vocabulary = {}\n",
        "\n",
        "for i in range(0,len(train_sentences)):\n",
        "    train_sentences[i] = train_sentences[i].lower()\n",
        "    for word in train_sentences[i].split():\n",
        "        if word not in vocabulary:\n",
        "            vocabulary[word] = 1\n",
        "        else:\n",
        "            vocabulary[word]+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q_QmFhfyZ7M8"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = len(vocabulary))\n",
        "tokenizer.fit_on_texts(df_train['premise_hypothesis'])\n",
        "word2index = tokenizer.word_index\n",
        "vocab_size = len(word2index)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(df_train['premise_hypothesis'])\n",
        "valid_sequences = tokenizer.texts_to_sequences(df_valid['premise_hypothesis'])\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test['premise_hypothesis'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0N13KC4yaKWs"
      },
      "outputs": [],
      "source": [
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "max_length = 64\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "valid_padded = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando os word embeddings\n",
        "\n",
        "Vamos carregar os word embeddings de um modelo word2vec que foi treinado a partir do *corpus* GoogleNews, que possui aproximadamente $3$ bilhões de palavras. Cada palavra é representada por vetor de $300$ dimensões.\n",
        "\n",
        "Como se trata de um modelo word2vec, vamos utilizar o método ```load_word2vec_format``` para carregar os pesos para um modelo word2vec. Isso ocorre por meio da classe ```KeyedVectors```. Como o arquivo desse embedding está em formato binário, devemos ajustar a flag ```binary=True```. Ademais, devido ao risco de estourarmos a memória RAM (nesse notebook), vamos limitar o vocabulário do modelo a $15000$ palavras."
      ],
      "metadata": {
        "id": "WdoKtiLu3dDN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W4SlpvQp25rs"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word_vectors= KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',\n",
        "                                                binary=True,\n",
        "                                                limit=15000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configurando a Embedding Layer para receber o Embedding word2vec \n",
        "\n",
        "Primeiramente, ajustamos a dimensão de saída da embedding layer que será igual à dimensão do embedding word2vec.\n",
        "\n"
      ],
      "metadata": {
        "id": "UB_SCP8ciuE0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XgGVZEDT4HXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a903c797-e61f-40ce-da64-0b5e3530268c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = len(word_vectors[0])\n",
        "\n",
        "print(embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazemos agora o seguinte processo:\n",
        "\n",
        "1.   Criamos a matriz de embeddings com dimensões \"tamanho do vocabulário $\\times$ dimensão da saída do embedding\", inicialmente zerada:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mD91BfhQoL46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
      ],
      "metadata": {
        "id": "KgQ-NcWHp0xM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   Como devemos configurar o embedding com os tokens do conjunto de treinamento, vamos processar palavra por palavra do *corpus* do SNLI, obter seu vetor (de dimensão ```embedding_dim```) por meio da embedding word2vec pré-treinada correspondente e incluí-la na matriz de embeddings.\n",
        "\n",
        "**Atenção:** caso uma palavra da parte de treinamento do *corpus* seja desconhecida ao word embedding, devemos (veja o else) gerar um vetor de dimensão ```embedding_dim``` contendo valores aleatórios ou zeros. No exemplo abaixo, os valores aleatórios seguem uma distribuição normal de média zero e desvio-padrão igual a $1$."
      ],
      "metadata": {
        "id": "1nWE92qup7yL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AlqGoFBhyk5Q"
      },
      "outputs": [],
      "source": [
        "for word, i in word2index.items():\n",
        "    if word in word_vectors:\n",
        "        embedding_vector = word_vectors[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        embedding_matrix[i] = np.random.normal(0,1,embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A embedding layer deve ser configurada da seguinte maneira para receber os pesos de um modelo word2vec que foram treinados a partir de um *corpus* grande (como o Google News ou Wikipedia):\n",
        "\n",
        "* Colocar como ```input_dim``` o tamanho do vocabulário (cada palavra é um eixo no espaço de características) e ```output_dim``` as dimensões do embedding (e dimensão do *word vector*);\n",
        "* Inicializar os pesos dos embeddings utilizando a matriz de embeddings\n",
        "* É importante ajustar o parâmetro ```trainable=False``` para prevenir que os pesos da camada de Embedding sejam alterados durante o treinamento."
      ],
      "metadata": {
        "id": "2ziW7UuY0M2i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H1S6MS_6xj6_"
      },
      "outputs": [],
      "source": [
        "embedding_layer = Embedding(input_dim = vocab_size,\n",
        "                            output_dim = embedding_dim,\n",
        "                            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                            input_length=max_length,\n",
        "                            trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segue uma arquitetura simples para predição podemos fazer a inferência de uma premissa para uma hipótese. A adição de camadas recorrentes (SimpleRNN, LSTM, GRU) ou Densa são importantes para aprender os padrões dos dados de interesse e que estão sendo classificados (no caso, o corpus de inferência de linguagem natural):\n",
        "\n",
        "*Homework: tente diferentes arquiteturas para melhorar os resultados obtidos nesse notebook!*"
      ],
      "metadata": {
        "id": "8POI5Ujx1imc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "egA0hMxsbgB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e44d7d2-6307-4d6c-ae32-93d2fc8d9889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 64, 300)           13635300  \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 64)                23360     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,658,920\n",
            "Trainable params: 23,620\n",
            "Non-trainable params: 13,635,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(SimpleRNN(64,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4,activation=\"softmax\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cVdwP7P3btU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ae0651-f862-41bd-9d4c-a080370500f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8597/8597 [==============================] - 422s 49ms/step - loss: 1.1208 - accuracy: 0.3319 - val_loss: 1.1859 - val_accuracy: 0.3328\n",
            "Epoch 2/10\n",
            "8597/8597 [==============================] - 415s 48ms/step - loss: 1.1107 - accuracy: 0.3329 - val_loss: 1.1844 - val_accuracy: 0.3279\n",
            "Epoch 3/10\n",
            "8597/8597 [==============================] - 416s 48ms/step - loss: 1.1103 - accuracy: 0.3341 - val_loss: 1.1857 - val_accuracy: 0.3237\n",
            "Epoch 4/10\n",
            "8597/8597 [==============================] - 419s 49ms/step - loss: 1.1098 - accuracy: 0.3332 - val_loss: 1.1839 - val_accuracy: 0.3331\n",
            "Epoch 5/10\n",
            "8597/8597 [==============================] - 418s 49ms/step - loss: 1.1096 - accuracy: 0.3319 - val_loss: 1.1926 - val_accuracy: 0.3279\n",
            "Epoch 6/10\n",
            "8597/8597 [==============================] - 412s 48ms/step - loss: 1.1092 - accuracy: 0.3345 - val_loss: 1.1831 - val_accuracy: 0.3280\n",
            "Epoch 7/10\n",
            "8597/8597 [==============================] - 413s 48ms/step - loss: 1.1092 - accuracy: 0.3338 - val_loss: 1.1884 - val_accuracy: 0.3330\n",
            "Epoch 8/10\n",
            "8597/8597 [==============================] - 411s 48ms/step - loss: 1.1090 - accuracy: 0.3337 - val_loss: 1.1852 - val_accuracy: 0.3329\n",
            "Epoch 9/10\n",
            "8597/8597 [==============================] - 414s 48ms/step - loss: 1.1088 - accuracy: 0.3352 - val_loss: 1.1922 - val_accuracy: 0.3235\n",
            "Epoch 10/10\n",
            "8597/8597 [==============================] - 414s 48ms/step - loss: 1.1088 - accuracy: 0.3312 - val_loss: 1.1855 - val_accuracy: 0.3331\n"
          ]
        }
      ],
      "source": [
        "sgd = SGD(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=sgd,metrics=['accuracy'])\n",
        "history = model.fit(train_padded,y_train,validation_data=(valid_padded,y_valid),batch_size=32,epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kUCsIvdQb0jr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "66138f23-6bc3-46b6-8ef2-8711b4cf87f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training set','validation set'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executando-se testes dos dados de teste:"
      ],
      "metadata": {
        "id": "yETsr0G46fLq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qCHm8yDUb3sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1867f37-d1e0-4c61-b90e-7b6c74b41fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       176\n",
            "           1       0.34      1.00      0.50      3368\n",
            "           2       0.50      0.00      0.00      3219\n",
            "           3       0.00      0.00      0.00      3237\n",
            "\n",
            "    accuracy                           0.34     10000\n",
            "   macro avg       0.21      0.25      0.13     10000\n",
            "weighted avg       0.27      0.34      0.17     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_prob = model.predict(test_padded)\n",
        "y_pred = np.argmax(y_prob,axis=1)\n",
        "print(classification_report(y_test_int,y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyP+sd6Xw73h5MtVNBX+x5+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}