{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cic0087_natural_language_processing/blob/main/cap4_2_sentiment_analysis_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpkeAnnOM-Ln"
      },
      "source": [
        "# Capítulo 4 - Redes Neurais Recorrentes\n",
        "\n",
        "## 4.3. Estudo de caso: Análise de Sentimentos utilizando uma Long Short Term Memory\n",
        "\n",
        "### Tarefa: classificação de polaridade em tweets\n",
        "\n",
        "Classificar um *tweet* em alguma das três polaridades: positiva (*positive*), negativa (*negative*) e positiva (*neutral*).\n",
        "\n",
        "### O *corpus*\n",
        "\n",
        "Para isso, vamos precisar utilizar as bibliotecas keras, tensorflow, numpy, sklearn, matplotlib.\n",
        "\n",
        "Fonte: [SemEval-2013 Task 2: Sentiment Analysis in Twitter](https://aclanthology.org/S13-2052/)\n",
        "\n",
        "O *corpus* de tweets empregado nesse estudo de caso podem ser acessados na pasta \"corpus_tweets\" deste repositório. Segue a especificação de cada arquivo:\n",
        "\n",
        "*   ```twitter-2013train-A.txt```: conjunto de tweets para treinamento\n",
        "*   ```twitter-2013dev-A.txt```: conjunto de tweets para validação\n",
        "*   ```twitter-2013test-A.txt```: conjunto de tweets para testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9-mA1ZKFmpUk"
      },
      "outputs": [],
      "source": [
        "#!pip install -U keras\n",
        "#!pip install -U tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d_kI-a9tsUFc"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Dropout, Flatten, Embedding, SimpleRNN\n",
        "from keras.datasets import reuters\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf19ddaLY9zF"
      },
      "source": [
        "### Carregamento do corpus para Pandas DataFrames\n",
        "\n",
        "\n",
        "\n",
        "**PS.:** Mais informações sobre a divisão de um conjunto de dados em treinamento, validação e teste, você encontra nesse [link](https://machinelearningmastery.com/difference-test-validation-datasets/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LQlVP9RXmWKN"
      },
      "outputs": [],
      "source": [
        "path_train = 'twitter-2013train-A.txt'\n",
        "path_valid = 'twitter-2013dev-A.txt'\n",
        "path_test = 'twitter-2013test-A.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W_CkgJDqrxrF",
        "outputId": "e7a76039-373d-4e58-aae4-dbd8ed82b93b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   id  polarity  \\\n",
              "0  264183816548130816  positive   \n",
              "1  263405084770172928  negative   \n",
              "2  262163168678248449  negative   \n",
              "3  264249301910310912  negative   \n",
              "4  262682041215234048   neutral   \n",
              "\n",
              "                                                text  \n",
              "0  Gas by my house hit $3.39!!!! I\\u2019m going t...  \n",
              "1  Theo Walcott is still shit\\u002c watch Rafa an...  \n",
              "2  its not that I\\u2019m a GSP fan\\u002c i just h...  \n",
              "3  Iranian general says Israel\\u2019s Iron Dome c...  \n",
              "4  Tehran\\u002c Mon Amour: Obama Tried to Establi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17e03e1c-0c01-4af5-9171-50d67a89d1a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264183816548130816</td>\n",
              "      <td>positive</td>\n",
              "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263405084770172928</td>\n",
              "      <td>negative</td>\n",
              "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262163168678248449</td>\n",
              "      <td>negative</td>\n",
              "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>264249301910310912</td>\n",
              "      <td>negative</td>\n",
              "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262682041215234048</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17e03e1c-0c01-4af5-9171-50d67a89d1a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17e03e1c-0c01-4af5-9171-50d67a89d1a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17e03e1c-0c01-4af5-9171-50d67a89d1a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_train = pd.read_csv(path_train, names=[\"id\",\"polarity\",\"text\"],encoding='utf8', sep='\\t')\n",
        "df_valid = pd.read_csv(path_valid, names=[\"id\",\"polarity\",\"text\"],encoding='utf8', sep='\\t')\n",
        "df_test = pd.read_csv(path_test, names=[\"id\",\"polarity\",\"text\"],encoding='utf8', sep='\\t')\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx7KJLSPcwUX",
        "outputId": "03c9241b-04c6-4303-ff6c-f06ce9fb8dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O conjunto de treinamento possui 9684 tweets\n",
            "O conjunto de validação possui 1654 tweets\n",
            "O conjunto de testes possui 3547 tweets\n"
          ]
        }
      ],
      "source": [
        "print(f\"O conjunto de treinamento possui {df_train.shape[0]} tweets\")\n",
        "print(f\"O conjunto de validação possui {df_valid.shape[0]} tweets\")\n",
        "print(f\"O conjunto de testes possui {df_test.shape[0]} tweets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Px27il9UkoN"
      },
      "source": [
        "Remove o atributo \"id\", uma vez que não precisaremos dele para a tarefa de classificação de polaridade de tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_rvrjHJ6UkwM",
        "outputId": "ccf595ff-646f-47e0-f4bf-2c871af6e395"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      polarity                                               text\n",
              "0     positive  @jjuueellzz down in the Atlantic city, ventnor...\n",
              "1     positive  Musical awareness: Great Big Beautiful Tomorro...\n",
              "2      neutral  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...\n",
              "3     negative  Kapan sih lo ngebuktiin,jan ngomong doang Susa...\n",
              "4      neutral  Excuse the connectivity of this live stream, f...\n",
              "...        ...                                                ...\n",
              "3542  negative  Khaleda Zia's present India visit may have a b...\n",
              "3543   neutral  FYI, golf fans: @jameslepp will join Moj on We...\n",
              "3544  negative  @__Aniko you think mr.Calle let practice with ...\n",
              "3545  positive  Don't hide under your desk! It's just a salsa ...\n",
              "3546   neutral  Saturday flashmob on the music of The Runaways...\n",
              "\n",
              "[3547 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ce7c7a3-b125-4b4e-8287-d1d8b5f44edf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>@jjuueellzz down in the Atlantic city, ventnor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>Kapan sih lo ngebuktiin,jan ngomong doang Susa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Excuse the connectivity of this live stream, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>negative</td>\n",
              "      <td>Khaleda Zia's present India visit may have a b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3543</th>\n",
              "      <td>neutral</td>\n",
              "      <td>FYI, golf fans: @jameslepp will join Moj on We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3544</th>\n",
              "      <td>negative</td>\n",
              "      <td>@__Aniko you think mr.Calle let practice with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3545</th>\n",
              "      <td>positive</td>\n",
              "      <td>Don't hide under your desk! It's just a salsa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3546</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Saturday flashmob on the music of The Runaways...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3547 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ce7c7a3-b125-4b4e-8287-d1d8b5f44edf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ce7c7a3-b125-4b4e-8287-d1d8b5f44edf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ce7c7a3-b125-4b4e-8287-d1d8b5f44edf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train.drop(labels=['id'],axis=1)\n",
        "df_valid.drop(labels=['id'],axis=1)\n",
        "df_test.drop(labels=['id'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NhetYpklsyB7"
      },
      "outputs": [],
      "source": [
        "df_train['polarity'] = pd.Categorical(df_train['polarity'])\n",
        "df_valid['polarity'] = pd.Categorical(df_valid['polarity'])\n",
        "df_test['polarity'] = pd.Categorical(df_test['polarity'])\n",
        "\n",
        "y_train = df_train['polarity'].cat.codes\n",
        "y_valid = df_valid['polarity'].cat.codes\n",
        "y_test = df_test['polarity'].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtoXk9BoryXV",
        "outputId": "a6565634-2317-451a-9d15-def28b774e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor original da classe positive Transformação inteira: 2\n",
            "Valor original da classe negative Transformação inteira: 0\n",
            "Valor original da classe negative Transformação inteira: 0\n",
            "Valor original da classe negative Transformação inteira: 0\n",
            "Valor original da classe neutral Transformação inteira: 1\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,5):\n",
        "    v = df_train['polarity'][i]\n",
        "    print(f'Valor original da classe {v} Transformação inteira: {y_train[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V4Xx__cczY9p"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "num_classes = 3\n",
        "\n",
        "y_train_enc = to_categorical(y_train,3)\n",
        "y_valid_enc = to_categorical(y_valid,3)\n",
        "y_test_enc = to_categorical(y_test,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfLRKtQ3mKpm",
        "outputId": "ad8edac0-14d3-473b-ec0a-73ed11d0b1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet 0: valor original da classe 'positive'; mapeamento para inteiro: 2; representação one-hot-encoding [0,0,1]\n",
            "Tweet 1: valor original da classe 'negative'; mapeamento para inteiro: 0; representação one-hot-encoding [1,0,0]\n",
            "Tweet 2: valor original da classe 'negative'; mapeamento para inteiro: 0; representação one-hot-encoding [1,0,0]\n",
            "Tweet 3: valor original da classe 'negative'; mapeamento para inteiro: 0; representação one-hot-encoding [1,0,0]\n",
            "Tweet 4: valor original da classe 'neutral'; mapeamento para inteiro: 1; representação one-hot-encoding [0,1,0]\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,5):\n",
        "    v = df_train['polarity'][i]\n",
        "    print(f\"Tweet {i}: valor original da classe '{v}'; mapeamento para inteiro: {y_train[i]}; representação one-hot-encoding [{int(y_train_enc[i][0])},{int(y_train_enc[i][1])},{int(y_train_enc[i][2])}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jua1-8lRZhr"
      },
      "source": [
        "### Extração de características dos tweets\n",
        "\n",
        "Vamos tentar novamente. Dessa vez, vamos fazer um pré-processamento nos tweets que, certamente apresentam palavras que não acrescentam nada ao aprendizado do modelo, como:\n",
        "\n",
        "*   @\n",
        "*   URL\n",
        "*   RT\n",
        "*   Stopwords\n",
        "\n",
        "Criando então as função para remover essas stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "import string \n",
        "\n",
        "def clean_stopwords_shortwords(w):\n",
        "    \n",
        "    words = w.split() \n",
        "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
        "    return \" \".join(clean_words) \n",
        "\n",
        "def preprocess_tweet(sentence):\n",
        "    stopwords_list=stopwords.words('english')\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r'^RT[\\s]+', '', sentence)\n",
        "    sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
        "    sentence = re.sub(r'#', '', sentence)\n",
        "    sentence = re.sub(r'[0-9]', '', sentence)\n",
        "\n",
        "    sentence_clean = \"\"\n",
        "\n",
        "    for word in sentence.split():\n",
        "        if (word not in stopwords_list):\n",
        "            sentence_clean+=word+\" \"\n",
        "\n",
        "    for c in string.punctuation:\n",
        "        sentence_clean = sentence_clean.replace(c,\"\")\n",
        "    return sentence_clean\n",
        "\n",
        "def preprocess_tweets(X):\n",
        "\n",
        "    df = []\n",
        "\n",
        "    for string in X:\n",
        "        ans = preprocess_tweet(string)\n",
        "        df.append(ans)\n",
        "    \n",
        "    return pd.DataFrame(df,columns =['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmT4EhjZxXda",
        "outputId": "c501db7c-7b19-48f7-ad17-bc7d69101398"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_proc = preprocess_tweets(df_train['text'])\n",
        "df_valid_proc = preprocess_tweets(df_valid['text'])\n",
        "df_test_proc = preprocess_tweets(df_test['text'])"
      ],
      "metadata": {
        "id": "Kr2ZEceoxbqZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original tweet: {df_train['text'].iloc[0]}\")\n",
        "print(f\"Preprocessed tweet: {df_train_proc['text'].iloc[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G0tjUllxgFq",
        "outputId": "46d43df4-adb7-4ba1-8720-574f118c1f3d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tweet: Gas by my house hit $3.39!!!! I\\u2019m going to Chapel Hill on Sat. :)\n",
            "Preprocessed tweet: gas house hit  ium going chapel hill sat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x5CTJsW8cacH"
      },
      "outputs": [],
      "source": [
        "results = Counter()\n",
        "df_train_proc['text'].str.lower().str.split().apply(results.update)\n",
        "df_valid_proc['text'].str.lower().str.split().apply(results.update)\n",
        "df_test_proc['text'].str.lower().str.split().apply(results.update)\n",
        "total_vocab_size = len(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qwoESY8g21bp"
      },
      "outputs": [],
      "source": [
        "def qtde_termos_tweet(df):\n",
        "    soma = 0\n",
        "    for item in df:\n",
        "        soma += len(item)\n",
        "    media = soma/len(df)\n",
        "    print(f'Em média, cada tweets possui {media} palavras.')\n",
        "    return int(media)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo36NUe33AV_"
      },
      "source": [
        "Hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j7EjtvOkcv8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "060ea35a-6f90-4b21-fba0-0c742bfd9785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Em média, cada tweets possui 78.97614622057002 palavras.\n"
          ]
        }
      ],
      "source": [
        "media = qtde_termos_tweet(df_train_proc['text'])\n",
        "\n",
        "vocab_size = total_vocab_size\n",
        "embedding_dim = media//2\n",
        "max_length = media//2\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "bs=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jUZSUfO_cyCW"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(df_train_proc['text'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hhR9fSS7chou"
      },
      "outputs": [],
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(df_train_proc['text'])\n",
        "\n",
        "valid_sequences = tokenizer.texts_to_sequences(df_valid_proc['text'])\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test_proc['text'])\n",
        "\n",
        "X_train = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "X_valid = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUMbZxfTtROx"
      },
      "source": [
        "Segue o modelo LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0oQObrHtQYq",
        "outputId": "623ffe2d-d156-4571-b3c9-de2f12f6cab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 39, 39)            920205    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                9216      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 99        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 929,520\n",
            "Trainable params: 929,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=max_length, input_length=max_length))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OL9ZvwaiudTF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "\n",
        "opt = Adam(learning_rate=0.00001,decay=10-6)\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaFB_4xfugKV",
        "outputId": "24a99eb4-7183-47b9-e69b-d8e43bcdcd15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "152/152 [==============================] - 4s 9ms/step - loss: 1.0984 - accuracy: 0.3555 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 2/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0983 - accuracy: 0.3563 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 3/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0982 - accuracy: 0.3547 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 4/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0983 - accuracy: 0.3554 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 5/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0985 - accuracy: 0.3538 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 6/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0985 - accuracy: 0.3527 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 7/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0984 - accuracy: 0.3534 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 8/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0982 - accuracy: 0.3609 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 9/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0985 - accuracy: 0.3548 - val_loss: 1.0989 - val_accuracy: 0.3476\n",
            "Epoch 10/10\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0982 - accuracy: 0.3581 - val_loss: 1.0989 - val_accuracy: 0.3476\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,y_train_enc,validation_data=(X_valid,y_valid_enc),epochs=10,batch_size=bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sepT496a5MXH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphics(history, metric):\n",
        "    plt.plot(history.history[metric])\n",
        "    plt.plot(history.history['val_'+metric], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphics(history, 'loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "jofPBgoDXQMY",
        "outputId": "8ab8a257-f690-4ad8-e683-692c6ec912c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1aVfStSvph6",
        "outputId": "0afd983e-afc8-4e28-f72f-f8697ca53244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4158443808555603\n",
            "56/56 - 0s - 445ms/epoch - 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       559\n",
            "           1       0.00      0.00      0.00      1513\n",
            "           2       0.42      1.00      0.59      1475\n",
            "\n",
            "    accuracy                           0.42      3547\n",
            "   macro avg       0.14      0.33      0.20      3547\n",
            "weighted avg       0.17      0.42      0.24      3547\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "_, test_acc = model.evaluate(X_test, y_test_enc, verbose=0)\n",
        "print(test_acc)\n",
        "\n",
        "y_pred = model.predict(X_test, batch_size=bs, verbose=2)\n",
        "\n",
        "# get the class with highest probability for each sample\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "# get the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veja que no exemplo acima, os tweets de teste foram classificados apenas como pertencentes a uma única classe. Isso era esperado com base nos resultados obtidos nos dados de validação durante o treinamento.\n",
        "\n",
        "Caso você esteja enfrentando o mesmo comportamento acima, lembre-se sempre de analisar os valores da função *loss* que podem estar atingindo um mínimo local muito cedo. Você pode tentar as seguintes alternativas:\n",
        "\n",
        "\n",
        "*   Pré-processamento dos dados: pode ser que os dados estejam poluídos, desbalanceados, ou apresentando redundância\n",
        "*   Otimize os hiperparâmetros: tente variar a *learning rate* entre $[10^{-3},10^{-6}]$, como também o *batch size*\n",
        "*   Deixe sua rede mais profunda, mas coloque camadas Dropout para evitar a ocorrência de *Overfitting*\n",
        "\n",
        "\n",
        "### Modelo 2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yT9kFHzLN4Uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos tentar também novos hiperparâmetros:"
      ],
      "metadata": {
        "id": "T34AwhwLPvdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocab_size, output_dim=max_length, input_length=max_length))\n",
        "model2.add(LSTM(32))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(num_classes))\n",
        "model2.add(Activation('sigmoid'))\n",
        "print(model2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH5glZW8KYBG",
        "outputId": "1d8ab3b2-6ca1-4a5b-a9b6-7364b2a99b49"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 39, 39)            920205    \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 32)                9216      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 929,520\n",
            "Trainable params: 929,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=0.00001, decay=1e-6)\n",
        "model2.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "gXtmX2q-KgbW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(X_train,y_train_enc,validation_data=(X_valid,y_valid_enc),epochs=80,batch_size=bs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7pc6_x5Kjel",
        "outputId": "afd63750-c0a3-4e1c-aa1b-928aba931e99"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "152/152 [==============================] - 3s 8ms/step - loss: 1.0876 - accuracy: 0.4719 - val_loss: 1.0881 - val_accuracy: 0.4468\n",
            "Epoch 2/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0815 - accuracy: 0.4729 - val_loss: 1.0838 - val_accuracy: 0.4468\n",
            "Epoch 3/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0751 - accuracy: 0.4727 - val_loss: 1.0792 - val_accuracy: 0.4468\n",
            "Epoch 4/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0678 - accuracy: 0.4732 - val_loss: 1.0742 - val_accuracy: 0.4468\n",
            "Epoch 5/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0608 - accuracy: 0.4739 - val_loss: 1.0692 - val_accuracy: 0.4468\n",
            "Epoch 6/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0524 - accuracy: 0.4734 - val_loss: 1.0641 - val_accuracy: 0.4468\n",
            "Epoch 7/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0439 - accuracy: 0.4736 - val_loss: 1.0594 - val_accuracy: 0.4468\n",
            "Epoch 8/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0358 - accuracy: 0.4736 - val_loss: 1.0554 - val_accuracy: 0.4468\n",
            "Epoch 9/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0270 - accuracy: 0.4735 - val_loss: 1.0530 - val_accuracy: 0.4468\n",
            "Epoch 10/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0208 - accuracy: 0.4735 - val_loss: 1.0525 - val_accuracy: 0.4468\n",
            "Epoch 11/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0158 - accuracy: 0.4736 - val_loss: 1.0537 - val_accuracy: 0.4468\n",
            "Epoch 12/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0128 - accuracy: 0.4735 - val_loss: 1.0554 - val_accuracy: 0.4468\n",
            "Epoch 13/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0096 - accuracy: 0.4730 - val_loss: 1.0570 - val_accuracy: 0.4468\n",
            "Epoch 14/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0093 - accuracy: 0.4732 - val_loss: 1.0583 - val_accuracy: 0.4468\n",
            "Epoch 15/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0098 - accuracy: 0.4723 - val_loss: 1.0586 - val_accuracy: 0.4468\n",
            "Epoch 16/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0092 - accuracy: 0.4694 - val_loss: 1.0594 - val_accuracy: 0.4468\n",
            "Epoch 17/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0080 - accuracy: 0.4729 - val_loss: 1.0600 - val_accuracy: 0.4468\n",
            "Epoch 18/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0096 - accuracy: 0.4696 - val_loss: 1.0599 - val_accuracy: 0.4468\n",
            "Epoch 19/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4711 - val_loss: 1.0603 - val_accuracy: 0.4468\n",
            "Epoch 20/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0086 - accuracy: 0.4698 - val_loss: 1.0605 - val_accuracy: 0.4468\n",
            "Epoch 21/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0075 - accuracy: 0.4666 - val_loss: 1.0609 - val_accuracy: 0.4468\n",
            "Epoch 22/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0085 - accuracy: 0.4695 - val_loss: 1.0608 - val_accuracy: 0.4468\n",
            "Epoch 23/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0085 - accuracy: 0.4689 - val_loss: 1.0608 - val_accuracy: 0.4468\n",
            "Epoch 24/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0089 - accuracy: 0.4671 - val_loss: 1.0609 - val_accuracy: 0.4468\n",
            "Epoch 25/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0086 - accuracy: 0.4713 - val_loss: 1.0611 - val_accuracy: 0.4468\n",
            "Epoch 26/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0073 - accuracy: 0.4698 - val_loss: 1.0616 - val_accuracy: 0.4468\n",
            "Epoch 27/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0081 - accuracy: 0.4696 - val_loss: 1.0611 - val_accuracy: 0.4468\n",
            "Epoch 28/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0075 - accuracy: 0.4709 - val_loss: 1.0611 - val_accuracy: 0.4468\n",
            "Epoch 29/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0075 - accuracy: 0.4712 - val_loss: 1.0616 - val_accuracy: 0.4468\n",
            "Epoch 30/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0074 - accuracy: 0.4695 - val_loss: 1.0614 - val_accuracy: 0.4468\n",
            "Epoch 31/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0075 - accuracy: 0.4677 - val_loss: 1.0615 - val_accuracy: 0.4468\n",
            "Epoch 32/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0089 - accuracy: 0.4672 - val_loss: 1.0610 - val_accuracy: 0.4468\n",
            "Epoch 33/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0069 - accuracy: 0.4690 - val_loss: 1.0611 - val_accuracy: 0.4468\n",
            "Epoch 34/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0069 - accuracy: 0.4726 - val_loss: 1.0614 - val_accuracy: 0.4468\n",
            "Epoch 35/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0072 - accuracy: 0.4716 - val_loss: 1.0612 - val_accuracy: 0.4468\n",
            "Epoch 36/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0066 - accuracy: 0.4726 - val_loss: 1.0614 - val_accuracy: 0.4468\n",
            "Epoch 37/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0064 - accuracy: 0.4710 - val_loss: 1.0613 - val_accuracy: 0.4468\n",
            "Epoch 38/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0074 - accuracy: 0.4712 - val_loss: 1.0610 - val_accuracy: 0.4468\n",
            "Epoch 39/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0044 - accuracy: 0.4703 - val_loss: 1.0618 - val_accuracy: 0.4468\n",
            "Epoch 40/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0053 - accuracy: 0.4703 - val_loss: 1.0615 - val_accuracy: 0.4468\n",
            "Epoch 41/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0051 - accuracy: 0.4707 - val_loss: 1.0610 - val_accuracy: 0.4468\n",
            "Epoch 42/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0053 - accuracy: 0.4728 - val_loss: 1.0607 - val_accuracy: 0.4468\n",
            "Epoch 43/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0040 - accuracy: 0.4737 - val_loss: 1.0611 - val_accuracy: 0.4468\n",
            "Epoch 44/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0039 - accuracy: 0.4739 - val_loss: 1.0609 - val_accuracy: 0.4468\n",
            "Epoch 45/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0041 - accuracy: 0.4692 - val_loss: 1.0606 - val_accuracy: 0.4468\n",
            "Epoch 46/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0017 - accuracy: 0.4754 - val_loss: 1.0604 - val_accuracy: 0.4468\n",
            "Epoch 47/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 1.0016 - accuracy: 0.4728 - val_loss: 1.0608 - val_accuracy: 0.4468\n",
            "Epoch 48/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.9993 - accuracy: 0.4726 - val_loss: 1.0596 - val_accuracy: 0.4468\n",
            "Epoch 49/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.9974 - accuracy: 0.4706 - val_loss: 1.0594 - val_accuracy: 0.4468\n",
            "Epoch 50/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.9946 - accuracy: 0.4738 - val_loss: 1.0582 - val_accuracy: 0.4468\n",
            "Epoch 51/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.9908 - accuracy: 0.4738 - val_loss: 1.0562 - val_accuracy: 0.4468\n",
            "Epoch 52/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.9833 - accuracy: 0.4741 - val_loss: 1.0518 - val_accuracy: 0.4468\n",
            "Epoch 53/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.9707 - accuracy: 0.4767 - val_loss: 1.0473 - val_accuracy: 0.4468\n",
            "Epoch 54/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.9489 - accuracy: 0.4767 - val_loss: 1.0332 - val_accuracy: 0.4468\n",
            "Epoch 55/80\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.9120 - accuracy: 0.4882 - val_loss: 1.0146 - val_accuracy: 0.4619\n",
            "Epoch 56/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.8655 - accuracy: 0.5299 - val_loss: 0.9990 - val_accuracy: 0.4885\n",
            "Epoch 57/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.8274 - accuracy: 0.5823 - val_loss: 0.9901 - val_accuracy: 0.4940\n",
            "Epoch 58/80\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.8043 - accuracy: 0.6132 - val_loss: 0.9932 - val_accuracy: 0.4976\n",
            "Epoch 59/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.7873 - accuracy: 0.6291 - val_loss: 0.9992 - val_accuracy: 0.4982\n",
            "Epoch 60/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.7722 - accuracy: 0.6410 - val_loss: 1.0002 - val_accuracy: 0.4976\n",
            "Epoch 61/80\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.7604 - accuracy: 0.6505 - val_loss: 1.0028 - val_accuracy: 0.5000\n",
            "Epoch 62/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.7478 - accuracy: 0.6593 - val_loss: 1.0100 - val_accuracy: 0.5012\n",
            "Epoch 63/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.7370 - accuracy: 0.6685 - val_loss: 1.0063 - val_accuracy: 0.4940\n",
            "Epoch 64/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.7294 - accuracy: 0.6779 - val_loss: 1.0137 - val_accuracy: 0.4976\n",
            "Epoch 65/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.7161 - accuracy: 0.6808 - val_loss: 1.0206 - val_accuracy: 0.4988\n",
            "Epoch 66/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.7076 - accuracy: 0.6885 - val_loss: 1.0276 - val_accuracy: 0.5012\n",
            "Epoch 67/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.6968 - val_loss: 1.0277 - val_accuracy: 0.4940\n",
            "Epoch 68/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6846 - accuracy: 0.7031 - val_loss: 1.0353 - val_accuracy: 0.4958\n",
            "Epoch 69/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6769 - accuracy: 0.7068 - val_loss: 1.0420 - val_accuracy: 0.4952\n",
            "Epoch 70/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6683 - accuracy: 0.7124 - val_loss: 1.0433 - val_accuracy: 0.4946\n",
            "Epoch 71/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6559 - accuracy: 0.7221 - val_loss: 1.0525 - val_accuracy: 0.4958\n",
            "Epoch 72/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6436 - accuracy: 0.7246 - val_loss: 1.0681 - val_accuracy: 0.5018\n",
            "Epoch 73/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6339 - accuracy: 0.7285 - val_loss: 1.0683 - val_accuracy: 0.4952\n",
            "Epoch 74/80\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 0.6227 - accuracy: 0.7393 - val_loss: 1.0873 - val_accuracy: 0.5030\n",
            "Epoch 75/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6120 - accuracy: 0.7387 - val_loss: 1.1007 - val_accuracy: 0.5042\n",
            "Epoch 76/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.5999 - accuracy: 0.7487 - val_loss: 1.1044 - val_accuracy: 0.4982\n",
            "Epoch 77/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.5878 - accuracy: 0.7520 - val_loss: 1.1268 - val_accuracy: 0.5042\n",
            "Epoch 78/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.5761 - accuracy: 0.7601 - val_loss: 1.1326 - val_accuracy: 0.5030\n",
            "Epoch 79/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.5648 - accuracy: 0.7651 - val_loss: 1.1388 - val_accuracy: 0.4982\n",
            "Epoch 80/80\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.5532 - accuracy: 0.7703 - val_loss: 1.1678 - val_accuracy: 0.5042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "_, test_acc = model2.evaluate(X_test, y_test_enc, verbose=2)\n",
        "print(test_acc)\n",
        "\n",
        "y_pred = model2.predict(X_test, batch_size=bs, verbose=2)\n",
        "\n",
        "# get the class with highest probability for each sample\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "# get the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "gFQE_6Rlx2Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23cdb47b-a410-48e9-d6fc-921c304c0689"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111/111 - 0s - loss: 1.1590 - accuracy: 0.5489 - 326ms/epoch - 3ms/step\n",
            "0.5489145517349243\n",
            "56/56 - 0s - 422ms/epoch - 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.03      0.05       559\n",
            "           1       0.58      0.69      0.63      1513\n",
            "           2       0.51      0.60      0.55      1475\n",
            "\n",
            "    accuracy                           0.55      3547\n",
            "   macro avg       0.56      0.44      0.41      3547\n",
            "weighted avg       0.56      0.55      0.51      3547\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cap4_2_sentiment_analysis_lstm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZbIeNOHASox4VeBYEktnk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}