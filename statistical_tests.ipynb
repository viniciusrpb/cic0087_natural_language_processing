{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNo67+RthKNewiVEuV+dddN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cic0269_natural_language_processing/blob/main/statistical_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testes Estatísticos para Aprendizado de Máquina"
      ],
      "metadata": {
        "id": "McDWFWdIFbXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base no artigo [*Statistical Comparisons of Classifiers over Multiple Data Sets*](https://www.jmlr.org/papers/volume7/demsar06a/demsar06a.pdf), de Janez Demsar, 2006.\n",
        "\n",
        "### Teste de Hipótese pelo Teste de Wilcoxon\n",
        "\n",
        "Comparar o desempenho de dois classificadores em um mesmo dataset utilizando o *Wilcoxon Signed-Rank Test*.\n",
        "\n"
      ],
      "metadata": {
        "id": "mQiZnBH7FcI_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "87o2kqM3FW3h"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import wilcoxon, friedmanchisquare, rankdata\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seja o conjunto de dados Iris. Vamos pegar os dados:"
      ],
      "metadata": {
        "id": "Xg8TDkVxGiks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "hs5pE_HSGHLt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento"
      ],
      "metadata": {
        "id": "u97psHawINa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "7qwyxlrBINjW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procedimento Geral para Testes de Hipóteses\n",
        "\n",
        "1.   A partir do contexto do problema, identifique o parâmetro de interesse;\n",
        "2.   Estabeleça a hipótese nula $H_0$;\n",
        "3.   Especifique uma hipótese alternativa $H_1$;\n",
        "4.   Escolha um nível de significância $\\alpha$;\n",
        "5.   Determine uma estatística apropriada de teste;\n",
        "6.   Estabeleça a região de rejeição para a estatística;\n",
        "7.   Calcule quaisquer grandezas amostrais necessárias,substitua-as na equação para a estatística de teste e calcule aquele valor;\n",
        "8.   Decida se $H_0$ deve ou não ser rejeitada."
      ],
      "metadata": {
        "id": "FFVzup_SPvPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste de Wilcoxon\n",
        "\n",
        "Primeiramente, precisamos formular uma hipótese estatística, que é uma afirmação sobre os parâmetros de uma ou mais populações. Em aprendizado de máquina, o que seriam essas populações?\n",
        "\n",
        "Sabemos que a ideia é comparar os classificadores Naive Bayes e SVM e verificar se seus desempenhos (acertos na classificação) permitem identificar desempenhos similares ou não entre eles. Nesse caso, podemos estabelecer como hipótese nula $H_0$ que seus desempenhos (medidos pela F1-Score) são equivalentes.\n",
        "\n",
        "Vamos repetir uma amostragem aleatória 20 vezes (pode ser um K-Fold Cross Validation também):\n"
      ],
      "metadata": {
        "id": "po1JBh30HDGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = []\n",
        "\n",
        "for i in range(0,21):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34, stratify=y, random_state=i)\n",
        "\n",
        "    # SVM \n",
        "    svm  = SVC(gamma='auto')\n",
        "\n",
        "    scaler.fit(X_train)\n",
        "\n",
        "    X_train_std = scaler.transform(X_train)\n",
        "\n",
        "    svm.fit(X_train_std, y_train)\n",
        "\n",
        "    X_test_std = scaler.transform(X_test)\n",
        "\n",
        "    y_svm_pred = svm.predict(X_test_std)\n",
        "\n",
        "    # Naive Bayes\n",
        "    gnb = GaussianNB()\n",
        "    \n",
        "    gnb.fit(X_train_std, y_train)\n",
        "\n",
        "    y_gnb_pred = gnb.predict(X_test_std)\n",
        "\n",
        "    print(y_test)\n",
        "\n",
        "    print(y_svm_pred)\n",
        "\n",
        "    f1_svm = f1_score(y_test, y_svm_pred, average='macro')\n",
        "\n",
        "    f1_gnb = f1_score(y_test, y_gnb_pred, average='macro')\n",
        "\n",
        "    f1_scores.append([f1_svm,f1_gnb])"
      ],
      "metadata": {
        "id": "e9ZEZDP4G1fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = np.array(f1_scores)"
      ],
      "metadata": {
        "id": "UzwhYWq3MtT2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando as F1-Scores para cada amostragem aleatória:"
      ],
      "metadata": {
        "id": "U20LBCUkK9fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(f1_scores, columns = ['SVM', 'Gaussian Naive-Bayes'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "w6jHe8zlK9m7",
        "outputId": "cd889fe3-2616-4729-dc36-dd6cc9ab0814"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         SVM  Gaussian Naive-Bayes\n",
              "0   0.960784              0.960784\n",
              "1   0.961874              0.980890\n",
              "2   1.000000              1.000000\n",
              "3   0.923656              0.961874\n",
              "4   0.923747              0.961874\n",
              "5   0.923747              0.942857\n",
              "6   0.923246              0.980952\n",
              "7   0.941126              0.960784\n",
              "8   0.884416              0.881944\n",
              "9   0.961874              0.942857\n",
              "10  1.000000              1.000000\n",
              "11  0.980890              0.980890\n",
              "12  0.923747              0.942857\n",
              "13  0.980890              0.980890\n",
              "14  0.980375              0.960648\n",
              "15  0.940715              0.940715\n",
              "16  0.980952              0.980952\n",
              "17  0.942670              0.923747\n",
              "18  0.980952              0.961874\n",
              "19  0.961623              0.980890\n",
              "20  0.942101              0.980890"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ea1367c-531d-4ef4-8cb2-0afb152f4e70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SVM</th>\n",
              "      <th>Gaussian Naive-Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.960784</td>\n",
              "      <td>0.960784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.961874</td>\n",
              "      <td>0.980890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.923656</td>\n",
              "      <td>0.961874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.923747</td>\n",
              "      <td>0.961874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.923747</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.923246</td>\n",
              "      <td>0.980952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.941126</td>\n",
              "      <td>0.960784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.884416</td>\n",
              "      <td>0.881944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.961874</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.980890</td>\n",
              "      <td>0.980890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.923747</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.980890</td>\n",
              "      <td>0.980890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.980375</td>\n",
              "      <td>0.960648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.940715</td>\n",
              "      <td>0.940715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.980952</td>\n",
              "      <td>0.980952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.942670</td>\n",
              "      <td>0.923747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.980952</td>\n",
              "      <td>0.961874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.961623</td>\n",
              "      <td>0.980890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.942101</td>\n",
              "      <td>0.980890</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ea1367c-531d-4ef4-8cb2-0afb152f4e70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ea1367c-531d-4ef4-8cb2-0afb152f4e70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ea1367c-531d-4ef4-8cb2-0afb152f4e70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wilcoxon(f1_scores[:,0], f1_scores[:,1], zero_method='zsplit')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzlYwtgQMRMX",
        "outputId": "4b0fe53c-f955-43d8-87f2-c4f78742a8b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/scipy/stats/_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
            "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WilcoxonResult(statistic=71.0, pvalue=0.12032389796169081)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O valor $\\rho$ de um teste de hipótese é o menor nível de significância que conduz à rejeição da hipótese nula $H_0$, com os dados fornecidos.\n",
        "\n",
        "\n",
        "O teste de Wilcoxon retornou um $\\rho$-valor próximo a $0.12$. Se o nível de significância for igual a $0.05$, podemos concluir que os desempenhos do SVM e o NB são equivalentes."
      ],
      "metadata": {
        "id": "FzSJY64XNVjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste de Nemenyi"
      ],
      "metadata": {
        "id": "wP8WXQXlNqpy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCbvbS_uNUbU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}